#  Multi-modal Multi-label Facial Action Unit Detection with Transformer (ABAW2022 submission)
*(Submission to the Affective Behavior Analysis in-the-wild ([ABAW3](https://ibug.doc.ic.ac.uk/resources/cvpr-2022-3rd-abaw/)) 2022 competition)*

This repository presents a Multi-modal Transformer based model for Multi-label Facial Action Unit Detection 

## Pre-trained Models
The pretrained model is available atï¼š
[Model weight](https://pan.baidu.com/s/1nkbK5EIMfrC9vTHujwHlQQ) with extract code: 7x18 

## Requirements
torch                    1.6.0, 
torchaudio               0.6, 
tqdm, 
Numpy, 
OpenCV 4.2.0
lmdb
einops

## Reference
part of code is from

[Former-DFER](https://github.com/zengqunzhao/Former-DFER)

[Two-Stream Aural-Visual Affect Analysis in the Wild](https://github.com/kuhnkeF/ABAW2020TNT)


